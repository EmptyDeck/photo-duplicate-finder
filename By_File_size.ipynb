{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File duplicate finder by size\n",
    "\n",
    "This code tries to find duplicated file by file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_duplicate_files(folder_path, scan_subfolders=False):\n",
    "    \"\"\"\n",
    "    Finds duplicate files within a folder and optionally its subfolders.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder to scan.\n",
    "        scan_subfolders (bool, optional): Whether to scan subfolders. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are file hashes and values are lists of file paths\n",
    "              with that hash (duplicates).\n",
    "    \"\"\"\n",
    "    file_hashes = {}\n",
    "    scanned_files_count = 0\n",
    "\n",
    "    if scan_subfolders:\n",
    "        file_list = []\n",
    "        print(\"1/2\")\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in tqdm(files):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "    else:\n",
    "        file_list = []\n",
    "        for f in tqdm(os.listdir(folder_path), desc=\"Scanning files\"):\n",
    "            file_path = os.path.join(folder_path, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                file_list.append(file_path)\n",
    "    progress_bar = tqdm(file_list, desc=\"Scanning files\", unit=\"file\")\n",
    "    print(\"2/2\")\n",
    "    for file_path in progress_bar:\n",
    "        scanned_files_count += 1\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                file_content = file.read()\n",
    "                file_hash = hashlib.sha256(file_content).hexdigest() # Using SHA256 for robust hashing\n",
    "\n",
    "                if file_hash in file_hashes:\n",
    "                    file_hashes[file_hash].append(file_path)\n",
    "                else:\n",
    "                    file_hashes[file_hash] = [file_path]\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {file_path}. Skipping. Error: {e}\") # Basic error handling - skip file\n",
    "\n",
    "    return file_hashes, scanned_files_count\n",
    "\n",
    "def move_duplicate_files(duplicate_groups, folder_path):\n",
    "    \"\"\"\n",
    "    Moves duplicate files to a '!duplication' folder within the specified folder.\n",
    "\n",
    "    Args:\n",
    "        duplicate_groups (dict): A dictionary of duplicate file groups (output from find_duplicate_files).\n",
    "        folder_path (str): The base folder path where the '!duplication' folder will be created.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of duplicate files moved.\n",
    "    \"\"\"\n",
    "    duplication_folder = os.path.join(folder_path, \"!duplication\")\n",
    "    if not os.path.exists(duplication_folder):\n",
    "        os.makedirs(duplication_folder) # Create the duplication folder if it doesn't exist\n",
    "\n",
    "    moved_files_count = 0\n",
    "    for hash_value, file_paths in duplicate_groups.items():\n",
    "        if len(file_paths) > 1: # Only consider groups with more than one file as duplicates\n",
    "            # Keep the first file as original, move the rest\n",
    "            original_file = file_paths[0]\n",
    "            duplicate_files = file_paths[1:]\n",
    "\n",
    "            for duplicate_file in duplicate_files:\n",
    "                try:\n",
    "                    destination_path = os.path.join(duplication_folder, os.path.basename(duplicate_file))\n",
    "                    os.rename(duplicate_file, destination_path) # Use rename for move within same filesystem (faster)\n",
    "                    moved_files_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error moving file: {duplicate_file} to {duplication_folder}. Skipping. Error: {e}\") # Error handling for moving\n",
    "\n",
    "    return moved_files_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning files: 100%|██████████| 55974/55974 [04:47<00:00, 194.97it/s] \n",
      "Scanning files:   0%|          | 0/55973 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning files: 100%|██████████| 55973/55973 [14:34<00:00, 64.01file/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scan Summary ---\n",
      "Total files scanned: 55973\n",
      "Duplicate files found: 291\n",
      "Duplicate files moved to '!duplication' folder: 291\n",
      "--- Script finished ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    folder_path = input(\"Put the folder directory here: \")\n",
    "    scan_subfolders_choice = input(\"Scan subfolders as well? (yes/no): \").lower()\n",
    "    scan_subfolders = scan_subfolders_choice == 'yes'\n",
    "\n",
    "    duplicate_hashes, scanned_count = find_duplicate_files(folder_path, scan_subfolders)\n",
    "\n",
    "    duplicates_found = 0\n",
    "    for hash_value in duplicate_hashes:\n",
    "        if len(duplicate_hashes[hash_value]) > 1:\n",
    "            duplicates_found += len(duplicate_hashes[hash_value]) - 1 # Subtract 1 because one is kept as original\n",
    "\n",
    "    moved_count = move_duplicate_files(duplicate_hashes, folder_path)\n",
    "\n",
    "    print(\"\\n--- Scan Summary ---\")\n",
    "    print(f\"Total files scanned: {scanned_count}\")\n",
    "    print(f\"Duplicate files found: {duplicates_found}\")\n",
    "    print(f\"Duplicate files moved to '!duplication' folder: {moved_count}\")\n",
    "    print(\"--- Script finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
